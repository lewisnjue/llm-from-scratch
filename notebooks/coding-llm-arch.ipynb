{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d2841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d27119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A placeholder GPT model architecture class \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05017e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self,normalized_shape,eps=1e-5): \n",
    "        super().__init__() \n",
    "    \n",
    "    def forward(self,x): \n",
    "        return x # also not useful will will fix that later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fb4783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module): \n",
    "    def __init__(self,cfg:dict=GPT_CONFIG_124M):\n",
    "        super().__init__() \n",
    "        self.cfg = cfg # :(\n",
    "        \n",
    "    def forward(self,x): \n",
    "        return x  # this block has nothing and just returns its input  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7371121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummpyGPTModel(nn.Module): \n",
    "    def __init__(self,cfg:dict=GPT_CONFIG_124M):\n",
    "        super().__init__() \n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim']) \n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'],cfg['vocab_size'],bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self,in_idx:torch.Tensor): \n",
    "        batch_size , seq_len = in_idx.shape \n",
    "        tok_embeds = self.tok_emb(in_idx) \n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len,device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds # B,T,C \n",
    "        x = self.drop_emb(x) \n",
    "        x  = self.trf_blocks(x) # B,T,C \n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x) # B,T,vocab_size \n",
    "        return logits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "270d88a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60d7d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123) \n",
    "model = DummpyGPTModel(GPT_CONFIG_124M) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55197966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edec2e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# normalizing activatins with layer normalization \n",
    "\n",
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5) \n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU()) \n",
    "\n",
    "out  = layer(batch_example) \n",
    "print(out); print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3357639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(out,dim=-1,keepdim=True) \n",
    "var = out.var(dim=-1,keepdim=True) \n",
    "\n",
    "print(\"Mean:\\n\",mean) \n",
    "print(\"Variance\\n\",var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14fb7077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var) \n",
    "\n",
    "mean = out_norm.mean(dim=-1,keepdim=True) \n",
    "var = out_norm.var(dim=-1,keepdim=True) \n",
    "print(\"Normalized layer outputs:\\n\",out_norm) \n",
    "print(\"Mean:\\n\",mean) \n",
    "print(\"Variance:\\n\",var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35f627db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56458f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nIn our variance calculation method, we use an implemenation detail by setting \\nunbiased=False, this mean , in the varaince calculation , we divide by the \\nnumer of inputs n in the variance formula. This approach does not apply bessels correction \\nwhich typicaly uses n-1 instaed of n in the denominator to adjust for \\nbias in sample varaince . For LLLMs , where the embedding dimenstin n is significantly \\nlarge , the difference between n and n-1 is practically negligible.  i choose this approach \\nto ensure compatibiltiy the the GPT-2 model normalization layer and becasue it refrect \\nTensorflows default behaviour which is used to implement the original GPT-2 model. \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm(nn.Module): \n",
    "    def __init__(self,emb_dim): \n",
    "        super().__init__() \n",
    "        self.eps = 1e-5 \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) \n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) \n",
    "    \n",
    "    def forward(self,x): \n",
    "        mean = x.mean(dim=-1,keepdim=True) \n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False) \n",
    "        norm_x  = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift # we are not forcing them to be gausian , model \n",
    "        # can do what it whant here :) \n",
    "\n",
    "\n",
    "\"\"\" \n",
    "In our variance calculation method, we use an implemenation detail by setting \n",
    "unbiased=False, this mean , in the varaince calculation , we divide by the \n",
    "numer of inputs n in the variance formula. This approach does not apply bessels correction \n",
    "which typicaly uses n-1 instaed of n in the denominator to adjust for \n",
    "bias in sample varaince . For LLLMs , where the embedding dimenstin n is significantly \n",
    "large , the difference between n and n-1 is practically negligible.  i choose this approach \n",
    "to ensure compatibiltiy the the GPT-2 model normalization layer and becasue it refrect \n",
    "Tensorflows default behaviour which is used to implement the original GPT-2 model. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e2cea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "\n",
    "out_ln = ln(batch_example) \n",
    "mean = out_ln.mean(dim=-1,keepdim=True) \n",
    "var = out_ln.var(dim=-1,unbiased=False,keepdim=True) \n",
    "print(\"Mean:\\n\",mean) \n",
    "print(\"Variance:\\n\",var) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34a81559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "if you are famiear with batch normalization, a common and traditional normalization\n",
    "method for neural networks, you may wonder how it compares to layer normalization. Unlike \n",
    "batch normalization, which normalizes across the batch dimenstin, layer normalization \n",
    "normalizes across the feature dimenstin. LLMS often rquires significant comutational \n",
    "resources , and the available hardware or the specific use case can dictate the \n",
    "batch size durin training or inference, since layer normalization normalizes each \n",
    "input independently of the batch size, if offers more flexibility and stability \n",
    "in these scenarios. \n",
    "\"\"\" \n",
    "#---------------------------------------------------------------------------\n",
    "# implementing a feed forward network with GELU activations \n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "        (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8fa6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "gelu, relu  = GELU(), nn.ReLU() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6132ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-3,3,100) \n",
    "y_gelu, y_relu  = gelu(x), relu(x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61175cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "for i, (y,label) in enumerate(zip([y_gelu,y_relu],[\"GELU\",\"RELU\"]),1): \n",
    "    plt.subplot(1,3,i) \n",
    "    plt.plot(x,y) \n",
    "    plt.title(f\"{label} activation function \" ) \n",
    "    plt.xlabel(\"x\") \n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa9bdb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module): \n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            GELU(), \n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self,x): \n",
    "        return self.layers(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ac5882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M) \n",
    "x = torch.rand(2,3,768) \n",
    "out = ffn(x) \n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee6ba1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding shortcut connections \n",
    "\n",
    "class ExampleDeepNeuralNetwork(nn.Module): \n",
    "    def __init__(self,layer_sizes,use_shortcut): \n",
    "        super().__init__() \n",
    "        self.use_shortcut = use_shortcut  \n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0],layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1],layer_sizes[2]),GELU()), \n",
    "            nn.Sequential(nn.Linear(layer_sizes[2],layer_sizes[3]),GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3],layer_sizes[4]),GELU()), \n",
    "            nn.Sequential(nn.Linear(layer_sizes[4],layer_sizes[5]),GELU())\n",
    "        ]) \n",
    "    \n",
    "    def forward(self,x): \n",
    "        for layer in self.layers: \n",
    "            layer_output = layer(x) \n",
    "            if self.use_shortcut and x.shape == layer_output.shape: \n",
    "                x = x + layer_output\n",
    "            else: \n",
    "                x = layer_output \n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc4331d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06127981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7725439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00040347169851884246\n",
      "layers.1.0.weight has gradient mean of 0.00024022319121286273\n",
      "layers.2.0.weight has gradient mean of 0.0014304080978035927\n",
      "layers.3.0.weight has gradient mean of 0.002797747263684869\n",
      "layers.4.0.weight has gradient mean of 0.010099290870130062\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input) \n",
    "# we can see the gradient becoming smaller , this is gradient vanishing problem :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e49b0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "# lets now use skip connections \n",
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baefa823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D_in = x.shape\n",
    "\n",
    "        Q = self.W_query(x)  # (B, T, D_out)\n",
    "        K = self.W_key(x)    # (B, T, D_out)\n",
    "        V = self.W_value(x)  # (B, T, D_out)\n",
    "\n",
    "\n",
    "        Q = Q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, T, head_dim)\n",
    "        K = K.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Attention scores\n",
    "        attn_scores = (Q @ K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (B, num_heads, T, T)\n",
    "\n",
    "        mask = self.mask[:T, :T].bool()\n",
    "        attn_scores = attn_scores.masked_fill(mask[None, None, :, :], float('-inf'))\n",
    "\n",
    "        # Softmax and dropout\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Apply attention\n",
    "        context = attn_weights @ V  # (B, num_heads, T, head_dim)\n",
    "\n",
    "        # Merge heads back\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, self.d_out)\n",
    "        context = self.out_proj(context)\n",
    "\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ed0f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module): \n",
    "    def __init__(self,cfg:dict):\n",
    "        super().__init__() \n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in= cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'], \n",
    "            context_length=cfg['context_length'], \n",
    "            num_heads = cfg['n_heads'], \n",
    "            dropout = cfg['drop_rate'], \n",
    "            qkv_bias=cfg['qkv_bias'] \n",
    "        )\n",
    "        self.ff = FeedForward(cfg) \n",
    "        self.norm1 = LayerNorm(cfg['emb_dim']) \n",
    "        self.norm2 = LayerNorm(cfg['emb_dim']) \n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate']) \n",
    "    \n",
    "    def forward(self,x): \n",
    "        shortcut = x \n",
    "        x = self.norm1(x) \n",
    "        x = self.att(x) \n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut \n",
    "\n",
    "        shortcut = x \n",
    "        x = self.norm2(x) \n",
    "        x = self.ff(x)  \n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut \n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f1ea87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "59cd8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module): \n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim']) \n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_dim']) \n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate']) \n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim']) \n",
    "\n",
    "        self.out_head = nn.Linear( \n",
    "            cfg['emb_dim'], cfg['vocab_size'],bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self,in_idx:torch.Tensor): \n",
    "        batch_size, sq_len =  in_idx.shape \n",
    "        tok_embeds = self.tok_emb(in_idx)  \n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(sq_len,device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds \n",
    "        x = self.drop_emb(x) \n",
    "        x = self.trf_blocks(x) \n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x) \n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27832745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "346364c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e5ad489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b537cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "total_params - sum(p.numel()\n",
    "for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters \"\n",
    "f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14562791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "# memory required \n",
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7ab7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating text \n",
    "def generate_text_simple(model,idx,max_new_tokens,context_size): \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] \n",
    "        with torch.no_grad(): \n",
    "            logits = model(idx_cond) \n",
    "        logits = logits[:,-1,:]\n",
    "        probas = torch.softmax(logits,dim=-1) \n",
    "        idx_next = torch.argmax(probas,dim=-1,keepdim=True) \n",
    "        idx = torch.cat((idx,idx_next),dim=1) \n",
    "    return idx   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1fcfd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f9a589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output lenght 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() \n",
    "\n",
    "out = generate_text_simple(\n",
    "    model = model  , \n",
    "    idx = encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size = GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "print(\"Output:\",out) \n",
    "print(\"Output lenght\",len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e62f62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab6054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56de06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
