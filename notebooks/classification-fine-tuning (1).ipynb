{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b34331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:40.084552Z",
     "iopub.status.busy": "2025-10-19T11:51:40.084372Z",
     "iopub.status.idle": "2025-10-19T11:51:40.091398Z",
     "shell.execute_reply": "2025-10-19T11:51:40.090841Z",
     "shell.execute_reply.started": "2025-10-19T11:51:40.084536Z"
    }
   },
   "outputs": [],
   "source": [
    "# dowloading and unzipping the dataset \n",
    "import urllib.request \n",
    "import zipfile \n",
    "import os \n",
    "from pathlib import Path \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebc313c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:40.093075Z",
     "iopub.status.busy": "2025-10-19T11:51:40.092815Z",
     "iopub.status.idle": "2025-10-19T11:51:40.106464Z",
     "shell.execute_reply": "2025-10-19T11:51:40.105826Z",
     "shell.execute_reply.started": "2025-10-19T11:51:40.093060Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_and_unzip_spam_data(\n",
    "            url,zip_path,extracted_path,data_file_path\n",
    "            ):\n",
    "            if data_file_path.exists():  \n",
    "                print(f\"{data_file_path} already exists. skipping dowload\") \n",
    "                return \n",
    "            with urllib.request.urlopen(url) as respose: \n",
    "                with open(zip_path,'wb') as out_file: \n",
    "                    out_file.write(respose.read())\n",
    "            \n",
    "            with zipfile.ZipFile(zip_path,'r') as zip_ref: \n",
    "                zip_ref.extractall(extracted_path) \n",
    "            original_file_path = Path(extracted_path) / \"SMSSpamCollection\" \n",
    "            os.rename(original_file_path,data_file_path) \n",
    "            print(f\"File download and saved as {data_file_path}\") \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654a0be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:40.107185Z",
     "iopub.status.busy": "2025-10-19T11:51:40.107014Z",
     "iopub.status.idle": "2025-10-19T11:51:41.064856Z",
     "shell.execute_reply": "2025-10-19T11:51:41.064260Z",
     "shell.execute_reply.started": "2025-10-19T11:51:40.107171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File download and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6025b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.065734Z",
     "iopub.status.busy": "2025-10-19T11:51:41.065502Z",
     "iopub.status.idle": "2025-10-19T11:51:41.347785Z",
     "shell.execute_reply": "2025-10-19T11:51:41.347010Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.065716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(data_file_path,sep='\\t',header=None,names=['Label','Text']) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c99319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.349424Z",
     "iopub.status.busy": "2025-10-19T11:51:41.348607Z",
     "iopub.status.idle": "2025-10-19T11:51:41.358424Z",
     "shell.execute_reply": "2025-10-19T11:51:41.357660Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.349378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# lets look at the class distribution \n",
    "\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f9b1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.359471Z",
     "iopub.status.busy": "2025-10-19T11:51:41.359149Z",
     "iopub.status.idle": "2025-10-19T11:51:41.380107Z",
     "shell.execute_reply": "2025-10-19T11:51:41.379464Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.359444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.459170013386881\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts()['ham'] / df['Label'].value_counts()['spam'])\n",
    "# ham is 6.5 times more than spam messages :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d4b5f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.382462Z",
     "iopub.status.busy": "2025-10-19T11:51:41.382220Z",
     "iopub.status.idle": "2025-10-19T11:51:41.393893Z",
     "shell.execute_reply": "2025-10-19T11:51:41.393219Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.382447Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "For simplicity , and because we prefer a small dataset(which will facilitate faster fine-tuning of the LLM) , \n",
    "we choose to undersample the dataset to include 747 instances for each class. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating a balanced dataset \n",
    "\n",
    "def create_balanced_dataset(df): \n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]  # counts the instances of spam  \n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(n=num_spam, random_state=42)   \n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]]) \n",
    "\n",
    "    return balanced_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "034e1b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.395330Z",
     "iopub.status.busy": "2025-10-19T11:51:41.394674Z",
     "iopub.status.idle": "2025-10-19T11:51:41.414656Z",
     "shell.execute_reply": "2025-10-19T11:51:41.414013Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.395286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "balanced_df = create_balanced_dataset(df) \n",
    "print(balanced_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e30e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.415642Z",
     "iopub.status.busy": "2025-10-19T11:51:41.415384Z",
     "iopub.status.idle": "2025-10-19T11:51:41.424141Z",
     "shell.execute_reply": "2025-10-19T11:51:41.423430Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.415627Z"
    }
   },
   "outputs": [],
   "source": [
    "balanced_df['Label'] = balanced_df['Label'].map({'ham':0,'spam':1})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4437cbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.424955Z",
     "iopub.status.busy": "2025-10-19T11:51:41.424782Z",
     "iopub.status.idle": "2025-10-19T11:51:41.436932Z",
     "shell.execute_reply": "2025-10-19T11:51:41.436359Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.424943Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting the dataset  \n",
    "\n",
    "def random_split(df,train_frac,validation_frac): \n",
    "    df = df.sample(\n",
    "        frac=1,random_state=123\n",
    "    ).reset_index(drop=True) \n",
    "\n",
    "    train_end = int(len(df) * train_frac) \n",
    "    validation_end = train_end + int(len(df) * validation_frac) \n",
    "\n",
    "    train_df = df[:train_end] \n",
    "    validation_df = df[train_end:validation_end] \n",
    "    test_df = df[validation_end:] \n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d99655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.437908Z",
     "iopub.status.busy": "2025-10-19T11:51:41.437683Z",
     "iopub.status.idle": "2025-10-19T11:51:41.451433Z",
     "shell.execute_reply": "2025-10-19T11:51:41.450774Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.437894Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = random_split(\n",
    "    balanced_df,0.7,0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15219e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.452252Z",
     "iopub.status.busy": "2025-10-19T11:51:41.452072Z",
     "iopub.status.idle": "2025-10-19T11:51:41.474534Z",
     "shell.execute_reply": "2025-10-19T11:51:41.473875Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.452239Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\",index=None) \n",
    "validation_df.to_csv(\"validation.csv\",index=None) \n",
    "test_df.to_csv(\"test.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eeee947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:41.475555Z",
     "iopub.status.busy": "2025-10-19T11:51:41.475339Z",
     "iopub.status.idle": "2025-10-19T11:51:46.041193Z",
     "shell.execute_reply": "2025-10-19T11:51:46.040467Z",
     "shell.execute_reply.started": "2025-10-19T11:51:41.475541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "# creating dat loaders \n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbdec4cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:46.042161Z",
     "iopub.status.busy": "2025-10-19T11:51:46.041920Z",
     "iopub.status.idle": "2025-10-19T11:51:49.642130Z",
     "shell.execute_reply": "2025-10-19T11:51:49.641361Z",
     "shell.execute_reply.started": "2025-10-19T11:51:46.042139Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beba88ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.643282Z",
     "iopub.status.busy": "2025-10-19T11:51:49.642882Z",
     "iopub.status.idle": "2025-10-19T11:51:49.650111Z",
     "shell.execute_reply": "2025-10-19T11:51:49.649370Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.643259Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset): \n",
    "    def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id = 50256): \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data['Text']\n",
    "        ]\n",
    "        if max_length is None: \n",
    "            self.max_length = self._longest_encoded_lenght() \n",
    "        else: \n",
    "            self.max_length = max_length \n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] \n",
    "                for encoded_text in self.encoded_texts\n",
    "            ] \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts \n",
    "        ]\n",
    "\n",
    "    def __getitem__(self,index): \n",
    "        encoded = self.encoded_texts[index] \n",
    "        label  = self.data.iloc[index]['Label'] \n",
    "        return (\n",
    "            torch.tensor(encoded,dtype=torch.long), \n",
    "            torch.tensor(label,dtype=torch.long)\n",
    "        )\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_lenght(self): \n",
    "        max_length = 0 \n",
    "        for encoded_text in self.encoded_texts: \n",
    "            encoded_lenght = len(encoded_text) \n",
    "            if encoded_lenght > max_length: \n",
    "                max_length = encoded_lenght \n",
    "        return max_length \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94beba87-f272-461a-90e0-3ca8ad22bb9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.651209Z",
     "iopub.status.busy": "2025-10-19T11:51:49.650970Z",
     "iopub.status.idle": "2025-10-19T11:51:49.705650Z",
     "shell.execute_reply": "2025-10-19T11:51:49.704877Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.651187Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file = \"train.csv\", \n",
    "    max_length = None , \n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "893adaa5-59f8-425b-8040-fb85db782525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.706740Z",
     "iopub.status.busy": "2025-10-19T11:51:49.706502Z",
     "iopub.status.idle": "2025-10-19T11:51:49.711278Z",
     "shell.execute_reply": "2025-10-19T11:51:49.710498Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.706718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7256e94e-4ad4-460e-8ef0-8974e77911c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.712257Z",
     "iopub.status.busy": "2025-10-19T11:51:49.712028Z",
     "iopub.status.idle": "2025-10-19T11:51:49.746507Z",
     "shell.execute_reply": "2025-10-19T11:51:49.745884Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.712234Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "csv_file=\"validation.csv\",\n",
    "max_length=train_dataset.max_length,\n",
    "tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "csv_file=\"test.csv\",\n",
    "max_length=train_dataset.max_length,\n",
    "tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af3521b-2f5c-42e3-a80a-27e580f29133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.747564Z",
     "iopub.status.busy": "2025-10-19T11:51:49.747334Z",
     "iopub.status.idle": "2025-10-19T11:51:49.751199Z",
     "shell.execute_reply": "2025-10-19T11:51:49.750503Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.747545Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa87fa75-efa8-4c9f-ae19-79cc920a5a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.752028Z",
     "iopub.status.busy": "2025-10-19T11:51:49.751864Z",
     "iopub.status.idle": "2025-10-19T11:51:49.771013Z",
     "shell.execute_reply": "2025-10-19T11:51:49.770198Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.752016Z"
    }
   },
   "outputs": [],
   "source": [
    "num_workers = 0 \n",
    "batch_size = 8 \n",
    "torch.manual_seed(123) \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers = num_workers, \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = num_workers, \n",
    "    drop_last = False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_dataset, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = num_workers, \n",
    "    drop_last = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338ecfbc-80b0-48fd-94e8-c83458b5fd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.772095Z",
     "iopub.status.busy": "2025-10-19T11:51:49.771753Z",
     "iopub.status.idle": "2025-10-19T11:51:49.919395Z",
     "shell.execute_reply": "2025-10-19T11:51:49.918611Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.772074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimenstions: torch.Size([8, 120])\n",
      "Label batch dimenstions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader: \n",
    "    pass \n",
    "print(\"Input batch dimenstions:\",input_batch.shape) \n",
    "print(\"Label batch dimenstions:\",target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e46e1a4-50a5-4d57-b2af-d39a79e503a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.924406Z",
     "iopub.status.busy": "2025-10-19T11:51:49.924154Z",
     "iopub.status.idle": "2025-10-19T11:51:49.928754Z",
     "shell.execute_reply": "2025-10-19T11:51:49.927982Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.924387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27969e87-072f-4dcd-a868-313bf07f1d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.929703Z",
     "iopub.status.busy": "2025-10-19T11:51:49.929463Z",
     "iopub.status.idle": "2025-10-19T11:51:49.943998Z",
     "shell.execute_reply": "2025-10-19T11:51:49.943248Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.929684Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the model with pretrained weights \n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\":50257,  \n",
    "    \"context_length\": 1024, \n",
    "    \"drop_rate\":0.0, \n",
    "    \"qkv_bias\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a22a93e3-b657-4677-931e-671307bd03f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.944946Z",
     "iopub.status.busy": "2025-10-19T11:51:49.944764Z",
     "iopub.status.idle": "2025-10-19T11:51:49.960908Z",
     "shell.execute_reply": "2025-10-19T11:51:49.960186Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.944931Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c974c63-5db9-401f-942b-30fcadc3beab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.961973Z",
     "iopub.status.busy": "2025-10-19T11:51:49.961706Z",
     "iopub.status.idle": "2025-10-19T11:51:49.976743Z",
     "shell.execute_reply": "2025-10-19T11:51:49.976005Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.961949Z"
    }
   },
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "269ed4e6-b822-4943-bc7b-f8e5ca0ebd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.977663Z",
     "iopub.status.busy": "2025-10-19T11:51:49.977444Z",
     "iopub.status.idle": "2025-10-19T11:51:49.991861Z",
     "shell.execute_reply": "2025-10-19T11:51:49.991107Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.977641Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b39a23a7-83fb-469d-a6fc-ce2de1cd71a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:51:49.992719Z",
     "iopub.status.busy": "2025-10-19T11:51:49.992498Z",
     "iopub.status.idle": "2025-10-19T11:52:02.718345Z",
     "shell.execute_reply": "2025-10-19T11:52:02.717789Z",
     "shell.execute_reply.started": "2025-10-19T11:51:49.992702Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 11:51:51.498594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760874711.703181      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760874711.760589      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
    "# Source for \"Build a Large Language Model From Scratch\"\n",
    "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
    "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path, backup_url)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination, backup_url=None):\n",
    "    def _attempt_download(download_url):\n",
    "        response = requests.get(download_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size and file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return True\n",
    "\n",
    "        block_size = 1024  # 1 KB\n",
    "        desc = os.path.basename(download_url)\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
    "            with open(destination, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=block_size):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        if _attempt_download(url):\n",
    "            return\n",
    "    except requests.exceptions.RequestException:\n",
    "        if backup_url is not None:\n",
    "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
    "            try:\n",
    "                if _attempt_download(backup_url):\n",
    "                    return\n",
    "            except requests.exceptions.RequestException:\n",
    "                pass\n",
    "\n",
    "        error_message = (\n",
    "            f\"Failed to download from both primary URL ({url})\"\n",
    "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
    "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
    "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
    "        )\n",
    "        print(error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Alternative way using `requests`\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceb89a3a-0a63-435a-aa63-5f911af70985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.719487Z",
     "iopub.status.busy": "2025-10-19T11:52:02.719009Z",
     "iopub.status.idle": "2025-10-19T11:52:02.727445Z",
     "shell.execute_reply": "2025-10-19T11:52:02.726631Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.719469Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D_in = x.shape\n",
    "\n",
    "        Q = self.W_query(x)  # (B, T, D_out)\n",
    "        K = self.W_key(x)    # (B, T, D_out)\n",
    "        V = self.W_value(x)  # (B, T, D_out)\n",
    "\n",
    "\n",
    "        Q = Q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, T, head_dim)\n",
    "        K = K.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Attention scores\n",
    "        attn_scores = (Q @ K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (B, num_heads, T, T)\n",
    "\n",
    "        mask = self.mask[:T, :T].bool()\n",
    "        attn_scores = attn_scores.masked_fill(mask[None, None, :, :], float('-inf'))\n",
    "\n",
    "        # Softmax and dropout\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Apply attention\n",
    "        context = attn_weights @ V  # (B, num_heads, T, head_dim)\n",
    "\n",
    "        # Merge heads back\n",
    "        context = context.transpose(1, 2).contiguous().view(B, T, self.d_out)\n",
    "        context = self.out_proj(context)\n",
    "\n",
    "        return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b8ec577-dbb3-47ef-89ed-3ca3b55e022f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.728486Z",
     "iopub.status.busy": "2025-10-19T11:52:02.728194Z",
     "iopub.status.idle": "2025-10-19T11:52:02.771810Z",
     "shell.execute_reply": "2025-10-19T11:52:02.771144Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.728463Z"
    }
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "        (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fe330e0-4d68-4328-8b6d-78cde1083eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.772686Z",
     "iopub.status.busy": "2025-10-19T11:52:02.772453Z",
     "iopub.status.idle": "2025-10-19T11:52:02.787605Z",
     "shell.execute_reply": "2025-10-19T11:52:02.786893Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.772666Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module): \n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            GELU(), \n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    \n",
    "    def forward(self,x): \n",
    "        return self.layers(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "952b86e5-0760-4d87-871b-44eb2c4ccd51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.788379Z",
     "iopub.status.busy": "2025-10-19T11:52:02.788201Z",
     "iopub.status.idle": "2025-10-19T11:52:02.800992Z",
     "shell.execute_reply": "2025-10-19T11:52:02.800349Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.788366Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module): \n",
    "    def __init__(self,emb_dim): \n",
    "        super().__init__() \n",
    "        self.eps = 1e-5 \n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) \n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) \n",
    "    \n",
    "    def forward(self,x): \n",
    "        mean = x.mean(dim=-1,keepdim=True) \n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False) \n",
    "        norm_x  = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift # we are not forcing them to be gausian , model \n",
    "        # can do what it whant here :) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25522503-61ab-4dcb-ad34-59826339fc11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.801914Z",
     "iopub.status.busy": "2025-10-19T11:52:02.801699Z",
     "iopub.status.idle": "2025-10-19T11:52:02.814627Z",
     "shell.execute_reply": "2025-10-19T11:52:02.813966Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.801901Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module): \n",
    "    def __init__(self,cfg:dict):\n",
    "        super().__init__() \n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in= cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'], \n",
    "            context_length=cfg['context_length'], \n",
    "            num_heads = cfg['n_heads'], \n",
    "            dropout = cfg['drop_rate'], \n",
    "            qkv_bias=cfg['qkv_bias'] \n",
    "        )\n",
    "        self.ff = FeedForward(cfg) \n",
    "        self.norm1 = LayerNorm(cfg['emb_dim']) \n",
    "        self.norm2 = LayerNorm(cfg['emb_dim']) \n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate']) \n",
    "    \n",
    "    def forward(self,x): \n",
    "        shortcut = x \n",
    "        x = self.norm1(x) \n",
    "        x = self.att(x) \n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut \n",
    "\n",
    "        shortcut = x \n",
    "        x = self.norm2(x) \n",
    "        x = self.ff(x)  \n",
    "        x = self.drop_shortcut(x) \n",
    "        x = x + shortcut \n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bc07f3f-d07e-4477-a981-b599e880adf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.815525Z",
     "iopub.status.busy": "2025-10-19T11:52:02.815194Z",
     "iopub.status.idle": "2025-10-19T11:52:02.831702Z",
     "shell.execute_reply": "2025-10-19T11:52:02.831182Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.815510Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "        \"Right: {right.shape}\"\n",
    "    )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c96581d-8287-476d-bf0f-298e7afc221d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.832482Z",
     "iopub.status.busy": "2025-10-19T11:52:02.832272Z",
     "iopub.status.idle": "2025-10-19T11:52:02.846510Z",
     "shell.execute_reply": "2025-10-19T11:52:02.845845Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.832468Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module): \n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim']) \n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_dim']) \n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate']) \n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg['emb_dim']) \n",
    "\n",
    "        self.out_head = nn.Linear( \n",
    "            cfg['emb_dim'], cfg['vocab_size'],bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self,in_idx:torch.Tensor): \n",
    "        batch_size, sq_len =  in_idx.shape \n",
    "        tok_embeds = self.tok_emb(in_idx)  \n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(sq_len,device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds \n",
    "        x = self.drop_emb(x) \n",
    "        x = self.trf_blocks(x) \n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x) \n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7238c32-1ada-4fa4-9305-bbd2b90332c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.847528Z",
     "iopub.status.busy": "2025-10-19T11:52:02.847242Z",
     "iopub.status.idle": "2025-10-19T11:52:02.862706Z",
     "shell.execute_reply": "2025-10-19T11:52:02.861979Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.847514Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model,idx,max_new_tokens,context_size): \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:,-context_size:] \n",
    "        with torch.no_grad(): \n",
    "            logits = model(idx_cond) \n",
    "        logits = logits[:,-1,:]\n",
    "        probas = torch.softmax(logits,dim=-1) \n",
    "        idx_next = torch.argmax(probas,dim=-1,keepdim=True) \n",
    "        idx = torch.cat((idx,idx_next),dim=1) \n",
    "    return idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1bdbac7-92ff-40b6-b16a-d580c0536a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.863837Z",
     "iopub.status.busy": "2025-10-19T11:52:02.863447Z",
     "iopub.status.idle": "2025-10-19T11:52:02.876769Z",
     "shell.execute_reply": "2025-10-19T11:52:02.876104Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.863821Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "755df43d-cbb0-4fff-a012-546c3e7fba83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:52:02.877546Z",
     "iopub.status.busy": "2025-10-19T11:52:02.877345Z",
     "iopub.status.idle": "2025-10-19T11:54:20.302253Z",
     "shell.execute_reply": "2025-10-19T11:54:20.301636Z",
     "shell.execute_reply.started": "2025-10-19T11:52:02.877532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 157kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 692kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 166kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:06<00:00, 3.94MiB/s]   \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.41MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 467kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 390kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c58b28f-64da-40f6-941e-fd239ee515c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:20.303201Z",
     "iopub.status.busy": "2025-10-19T11:54:20.302994Z",
     "iopub.status.idle": "2025-10-19T11:54:20.307118Z",
     "shell.execute_reply": "2025-10-19T11:54:20.306462Z",
     "shell.execute_reply.started": "2025-10-19T11:54:20.303177Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_token_ids(text,tokenizer): \n",
    "    encoded = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"}) \n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f198a18d-cac9-4057-aa30-ba21bfcf2edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:20.308131Z",
     "iopub.status.busy": "2025-10-19T11:54:20.307861Z",
     "iopub.status.idle": "2025-10-19T11:54:20.321656Z",
     "shell.execute_reply": "2025-10-19T11:54:20.321099Z",
     "shell.execute_reply.started": "2025-10-19T11:54:20.308117Z"
    }
   },
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids:torch.Tensor,tokenizer): \n",
    "    flat = token_ids.squeeze(0) # remove batch dimenstion \n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bb58158-a7f5-40af-8927-05b5d7b9db45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:20.322665Z",
     "iopub.status.busy": "2025-10-19T11:54:20.322441Z",
     "iopub.status.idle": "2025-10-19T11:54:21.588672Z",
     "shell.execute_reply": "2025-10-19T11:54:21.587979Z",
     "shell.execute_reply.started": "2025-10-19T11:54:20.322644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(text_1, tokenizer),\n",
    "max_new_tokens=15,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a2f8b3f-18a0-4b14-a7aa-29478d035ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:21.589694Z",
     "iopub.status.busy": "2025-10-19T11:54:21.589369Z",
     "iopub.status.idle": "2025-10-19T11:54:24.396651Z",
     "shell.execute_reply": "2025-10-19T11:54:24.395833Z",
     "shell.execute_reply.started": "2025-10-19T11:54:21.589675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "\" 'You are a winner you have been specially\"\n",
    "\" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(text_2, tokenizer),\n",
    "max_new_tokens=23,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b25211e0-a346-4656-b9bb-67e1f7fec0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.397732Z",
     "iopub.status.busy": "2025-10-19T11:54:24.397426Z",
     "iopub.status.idle": "2025-10-19T11:54:24.402988Z",
     "shell.execute_reply": "2025-10-19T11:54:24.402331Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.397708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "527ffe8f-b4a2-48da-b9b9-43a324d68485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.404070Z",
     "iopub.status.busy": "2025-10-19T11:54:24.403797Z",
     "iopub.status.idle": "2025-10-19T11:54:24.416977Z",
     "shell.execute_reply": "2025-10-19T11:54:24.416228Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.404054Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8c87f4b-7ad4-4764-98dc-45ad03abb641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.417972Z",
     "iopub.status.busy": "2025-10-19T11:54:24.417755Z",
     "iopub.status.idle": "2025-10-19T11:54:24.434846Z",
     "shell.execute_reply": "2025-10-19T11:54:24.434289Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.417953Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac91410f-0737-4925-bb2f-854a4ef9da58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.435827Z",
     "iopub.status.busy": "2025-10-19T11:54:24.435621Z",
     "iopub.status.idle": "2025-10-19T11:54:24.461657Z",
     "shell.execute_reply": "2025-10-19T11:54:24.461177Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.435814Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b845223-f263-41f1-8254-15e8fba5a011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.462434Z",
     "iopub.status.busy": "2025-10-19T11:54:24.462236Z",
     "iopub.status.idle": "2025-10-19T11:54:24.470699Z",
     "shell.execute_reply": "2025-10-19T11:54:24.470087Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.462421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab587a2b-c15e-4aec-b2fa-22491f7ca728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.471844Z",
     "iopub.status.busy": "2025-10-19T11:54:24.471373Z",
     "iopub.status.idle": "2025-10-19T11:54:24.537815Z",
     "shell.execute_reply": "2025-10-19T11:54:24.537226Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.471822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    print(\"Outputs:\\n\", outputs)\n",
    "    print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d3b003c-d43f-45e7-970c-6375e76d9eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.538669Z",
     "iopub.status.busy": "2025-10-19T11:54:24.538455Z",
     "iopub.status.idle": "2025-10-19T11:54:24.542968Z",
     "shell.execute_reply": "2025-10-19T11:54:24.542458Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.538654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7e2b211-b946-405c-ad28-e8e988229a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.544123Z",
     "iopub.status.busy": "2025-10-19T11:54:24.543565Z",
     "iopub.status.idle": "2025-10-19T11:54:24.556363Z",
     "shell.execute_reply": "2025-10-19T11:54:24.555808Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.544107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52ced38c-262a-4fb9-9bf0-b273814fc299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.557056Z",
     "iopub.status.busy": "2025-10-19T11:54:24.556907Z",
     "iopub.status.idle": "2025-10-19T11:54:24.568884Z",
     "shell.execute_reply": "2025-10-19T11:54:24.568229Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.557045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b98f36c-6402-4b6e-9538-ed00187ca944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.569799Z",
     "iopub.status.busy": "2025-10-19T11:54:24.569564Z",
     "iopub.status.idle": "2025-10-19T11:54:24.582104Z",
     "shell.execute_reply": "2025-10-19T11:54:24.581477Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.569779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d5e7f5d-93bd-463f-b94e-dd9b045b212a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.583304Z",
     "iopub.status.busy": "2025-10-19T11:54:24.582887Z",
     "iopub.status.idle": "2025-10-19T11:54:24.597386Z",
     "shell.execute_reply": "2025-10-19T11:54:24.596768Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.583284Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval() \n",
    "    correct_predictions, num_examples=0,0\n",
    "    if num_batches is None: \n",
    "        num_batches = len(data_loader)\n",
    "    else: \n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i, (input_batch,target_batch) in enumerate(data_loader): \n",
    "        if i < num_batches: \n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:] # logits of last ouput token\n",
    "            predicted_labels  = torch.argmax(logits,dim=-1)\n",
    "            num_examples += predicted_labels.shape[0] # how many examples in the batch \n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "951f7a4e-cabd-4f0e-a841-8995d04cd7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:24.598140Z",
     "iopub.status.busy": "2025-10-19T11:54:24.597985Z",
     "iopub.status.idle": "2025-10-19T11:54:26.524600Z",
     "shell.execute_reply": "2025-10-19T11:54:26.523994Z",
     "shell.execute_reply.started": "2025-10-19T11:54:24.598128Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device) \n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "test_loader, model, device, num_batches=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b0369e8-2b5d-427e-b751-49a2a48ad476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:26.525639Z",
     "iopub.status.busy": "2025-10-19T11:54:26.525380Z",
     "iopub.status.idle": "2025-10-19T11:54:26.529715Z",
     "shell.execute_reply": "2025-10-19T11:54:26.529010Z",
     "shell.execute_reply.started": "2025-10-19T11:54:26.525617Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eafcd69e-8704-48fa-8b13-f752012ac6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:26.530660Z",
     "iopub.status.busy": "2025-10-19T11:54:26.530398Z",
     "iopub.status.idle": "2025-10-19T11:54:26.544889Z",
     "shell.execute_reply": "2025-10-19T11:54:26.544432Z",
     "shell.execute_reply.started": "2025-10-19T11:54:26.530645Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0. \n",
    "    if len(data_loader) == 0: \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i, (input_batch,target_batch) in enumerate(data_loader): \n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e4c74b1-9e2a-4a70-9be9-91dbc701d562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:26.545963Z",
     "iopub.status.busy": "2025-10-19T11:54:26.545672Z",
     "iopub.status.idle": "2025-10-19T11:54:27.127207Z",
     "shell.execute_reply": "2025-10-19T11:54:27.126655Z",
     "shell.execute_reply.started": "2025-10-19T11:54:26.545943Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    train_loss  = calc_loss_loader(\n",
    "        train_loader,model,device,num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader,model,device,num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader,model,device,num_batches=5) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e33b255-e9c5-41b3-bce1-818f6f5d39be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:27.128142Z",
     "iopub.status.busy": "2025-10-19T11:54:27.127944Z",
     "iopub.status.idle": "2025-10-19T11:54:27.132196Z",
     "shell.execute_reply": "2025-10-19T11:54:27.131595Z",
     "shell.execute_reply.started": "2025-10-19T11:54:27.128126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.450\n",
      "Validation loss: 2.565\n",
      "Test loss: 2.325\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23cae55d-492b-496e-bb4e-895b3ef4cbfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:27.133267Z",
     "iopub.status.busy": "2025-10-19T11:54:27.132985Z",
     "iopub.status.idle": "2025-10-19T11:54:27.146213Z",
     "shell.execute_reply": "2025-10-19T11:54:27.145714Z",
     "shell.execute_reply.started": "2025-10-19T11:54:27.133252Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "    model,train_loader,val_loader,optimizer,device,\n",
    "    num_epochs,eval_freq,eval_iter):\n",
    "    train_losses,val_losses,train_accs,val_accs = [],[],[],[]\n",
    "    examples_seen,global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch,target_batch,model,device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0] # how many examples in the batch\n",
    "            global_step +=1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model,train_loader,val_loader,device,eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_losses)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                    )\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            val_loader,model,device,num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader,model,device,num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f483082a-9293-40fe-b164-e34e0b84b7e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:27.147033Z",
     "iopub.status.busy": "2025-10-19T11:54:27.146848Z",
     "iopub.status.idle": "2025-10-19T11:54:27.163462Z",
     "shell.execute_reply": "2025-10-19T11:54:27.162790Z",
     "shell.execute_reply.started": "2025-10-19T11:54:27.147020Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b29e224a-f870-45c0-8cbd-a687a738fa68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:27.164211Z",
     "iopub.status.busy": "2025-10-19T11:54:27.164020Z",
     "iopub.status.idle": "2025-10-19T11:54:27.177521Z",
     "shell.execute_reply": "2025-10-19T11:54:27.176892Z",
     "shell.execute_reply.started": "2025-10-19T11:54:27.164197Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04d00725-3403-4d7b-a164-109f85bed6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:54:27.178403Z",
     "iopub.status.busy": "2025-10-19T11:54:27.178141Z",
     "iopub.status.idle": "2025-10-19T11:55:05.782462Z",
     "shell.execute_reply": "2025-10-19T11:55:05.781840Z",
     "shell.execute_reply.started": "2025-10-19T11:54:27.178379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.160, Val loss 2.374\n",
      "Ep 1 (Step 000050): Train loss 0.654, Val loss 0.631\n",
      "Ep 1 (Step 000100): Train loss 0.531, Val loss 0.566\n",
      "Training accuracy: 75.00% | Validation accuracy: 75.00%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.462\n",
      "Ep 2 (Step 000200): Train loss 0.537, Val loss 0.390\n",
      "Ep 2 (Step 000250): Train loss 0.284, Val loss 0.340\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 3 (Step 000300): Train loss 0.488, Val loss 0.336\n",
      "Ep 3 (Step 000350): Train loss 0.291, Val loss 0.305\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 000400): Train loss 0.110, Val loss 0.114\n",
      "Ep 4 (Step 000450): Train loss 0.075, Val loss 0.078\n",
      "Ep 4 (Step 000500): Train loss 0.012, Val loss 0.051\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 5 (Step 000550): Train loss 0.173, Val loss 0.053\n",
      "Ep 5 (Step 000600): Train loss 0.189, Val loss 0.087\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Training completed in 0.64 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "train_classifier_simple(\n",
    "model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=50,\n",
    "eval_iter=5\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92b51934-f5d3-4745-95c5-cc01b7b8fae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:55:05.783648Z",
     "iopub.status.busy": "2025-10-19T11:55:05.783122Z",
     "iopub.status.idle": "2025-10-19T11:55:05.787015Z",
     "shell.execute_reply": "2025-10-19T11:55:05.786277Z",
     "shell.execute_reply.started": "2025-10-19T11:55:05.783630Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b236664-26d6-4601-b414-48ddae36ed1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T11:55:05.788238Z",
     "iopub.status.busy": "2025-10-19T11:55:05.787778Z",
     "iopub.status.idle": "2025-10-19T11:55:05.802831Z",
     "shell.execute_reply": "2025-10-19T11:55:05.802217Z",
     "shell.execute_reply.started": "2025-10-19T11:55:05.788210Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_values(\n",
    "    epochs_seen,examples_seen,train_values,val_values,label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    ax1.plot(epochs_seen,train_values,label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen,val_values,linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen,train_values,alpha=0)\n",
    "    ax2.set_xlabel(\"Example Seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7c1d0-5a36-4ef6-bb39-27b5574d8b6e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-19T11:58:51.993Z",
     "iopub.execute_input": "2025-10-19T11:55:05.803553Z",
     "iopub.status.busy": "2025-10-19T11:55:05.803372Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916427c-9271-4b05-aa6c-83150f04eb5a",
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-19T11:58:51.993Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "plot_values(\n",
    "epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf1514-83b7-4c9e-9cbd-f63e9da508cf",
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-19T11:58:51.994Z"
    }
   },
   "outputs": [],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02444756-6aed-4002-ac6b-8a8ffb2ae144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
