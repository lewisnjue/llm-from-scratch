{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d3b34331","cell_type":"code","source":"# dowloading and unzipping the dataset \nimport urllib.request \nimport zipfile \nimport os \nfrom pathlib import Path \n\nurl = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\nzip_path = \"sms_spam_collection.zip\"\nextracted_path = \"sms_spam_collection\"\ndata_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:40.084372Z","iopub.execute_input":"2025-10-19T11:51:40.084552Z","iopub.status.idle":"2025-10-19T11:51:40.091398Z","shell.execute_reply.started":"2025-10-19T11:51:40.084536Z","shell.execute_reply":"2025-10-19T11:51:40.090841Z"}},"outputs":[],"execution_count":1},{"id":"eebc313c","cell_type":"code","source":"def download_and_unzip_spam_data(\n            url,zip_path,extracted_path,data_file_path\n            ):\n            if data_file_path.exists():  \n                print(f\"{data_file_path} already exists. skipping dowload\") \n                return \n            with urllib.request.urlopen(url) as respose: \n                with open(zip_path,'wb') as out_file: \n                    out_file.write(respose.read())\n            \n            with zipfile.ZipFile(zip_path,'r') as zip_ref: \n                zip_ref.extractall(extracted_path) \n            original_file_path = Path(extracted_path) / \"SMSSpamCollection\" \n            os.rename(original_file_path,data_file_path) \n            print(f\"File download and saved as {data_file_path}\") \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:40.092815Z","iopub.execute_input":"2025-10-19T11:51:40.093075Z","iopub.status.idle":"2025-10-19T11:51:40.106464Z","shell.execute_reply.started":"2025-10-19T11:51:40.093060Z","shell.execute_reply":"2025-10-19T11:51:40.105826Z"}},"outputs":[],"execution_count":2},{"id":"654a0be6","cell_type":"code","source":"download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:40.107014Z","iopub.execute_input":"2025-10-19T11:51:40.107185Z","iopub.status.idle":"2025-10-19T11:51:41.064856Z","shell.execute_reply.started":"2025-10-19T11:51:40.107171Z","shell.execute_reply":"2025-10-19T11:51:41.064260Z"}},"outputs":[{"name":"stdout","text":"File download and saved as sms_spam_collection/SMSSpamCollection.tsv\n","output_type":"stream"}],"execution_count":3},{"id":"0e6025b9","cell_type":"code","source":"import pandas as pd \n\ndf = pd.read_csv(data_file_path,sep='\\t',header=None,names=['Label','Text']) \n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.065502Z","iopub.execute_input":"2025-10-19T11:51:41.065734Z","iopub.status.idle":"2025-10-19T11:51:41.347785Z","shell.execute_reply.started":"2025-10-19T11:51:41.065716Z","shell.execute_reply":"2025-10-19T11:51:41.347010Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  Label                                               Text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"a1c99319","cell_type":"code","source":"# lets look at the class distribution \n\nprint(df['Label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.348607Z","iopub.execute_input":"2025-10-19T11:51:41.349424Z","iopub.status.idle":"2025-10-19T11:51:41.358424Z","shell.execute_reply.started":"2025-10-19T11:51:41.349378Z","shell.execute_reply":"2025-10-19T11:51:41.357660Z"}},"outputs":[{"name":"stdout","text":"Label\nham     4825\nspam     747\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"id":"f4f9b1c8","cell_type":"code","source":"print(df['Label'].value_counts()['ham'] / df['Label'].value_counts()['spam'])\n# ham is 6.5 times more than spam messages :( ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.359149Z","iopub.execute_input":"2025-10-19T11:51:41.359471Z","iopub.status.idle":"2025-10-19T11:51:41.380107Z","shell.execute_reply.started":"2025-10-19T11:51:41.359444Z","shell.execute_reply":"2025-10-19T11:51:41.379464Z"}},"outputs":[{"name":"stdout","text":"6.459170013386881\n","output_type":"stream"}],"execution_count":6},{"id":"4d4b5f3d","cell_type":"code","source":"\"\"\" \nFor simplicity , and because we prefer a small dataset(which will facilitate faster fine-tuning of the LLM) , \nwe choose to undersample the dataset to include 747 instances for each class. \n\n\"\"\"\n\n# creating a balanced dataset \n\ndef create_balanced_dataset(df): \n    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]  # counts the instances of spam  \n    ham_subset = df[df[\"Label\"] == \"ham\"].sample(n=num_spam, random_state=42)   \n    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]]) \n\n    return balanced_df  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.382220Z","iopub.execute_input":"2025-10-19T11:51:41.382462Z","iopub.status.idle":"2025-10-19T11:51:41.393893Z","shell.execute_reply.started":"2025-10-19T11:51:41.382447Z","shell.execute_reply":"2025-10-19T11:51:41.393219Z"}},"outputs":[],"execution_count":7},{"id":"034e1b4c","cell_type":"code","source":"balanced_df = create_balanced_dataset(df) \nprint(balanced_df['Label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.394674Z","iopub.execute_input":"2025-10-19T11:51:41.395330Z","iopub.status.idle":"2025-10-19T11:51:41.414656Z","shell.execute_reply.started":"2025-10-19T11:51:41.395286Z","shell.execute_reply":"2025-10-19T11:51:41.414013Z"}},"outputs":[{"name":"stdout","text":"Label\nham     747\nspam    747\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"id":"66e30e06","cell_type":"code","source":"balanced_df['Label'] = balanced_df['Label'].map({'ham':0,'spam':1})  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.415384Z","iopub.execute_input":"2025-10-19T11:51:41.415642Z","iopub.status.idle":"2025-10-19T11:51:41.424141Z","shell.execute_reply.started":"2025-10-19T11:51:41.415627Z","shell.execute_reply":"2025-10-19T11:51:41.423430Z"}},"outputs":[],"execution_count":9},{"id":"4437cbee","cell_type":"code","source":"# splitting the dataset  \n\ndef random_split(df,train_frac,validation_frac): \n    df = df.sample(\n        frac=1,random_state=123\n    ).reset_index(drop=True) \n\n    train_end = int(len(df) * train_frac) \n    validation_end = train_end + int(len(df) * validation_frac) \n\n    train_df = df[:train_end] \n    validation_df = df[train_end:validation_end] \n    test_df = df[validation_end:] \n    return train_df, validation_df, test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.424782Z","iopub.execute_input":"2025-10-19T11:51:41.424955Z","iopub.status.idle":"2025-10-19T11:51:41.436932Z","shell.execute_reply.started":"2025-10-19T11:51:41.424943Z","shell.execute_reply":"2025-10-19T11:51:41.436359Z"}},"outputs":[],"execution_count":10},{"id":"13d99655","cell_type":"code","source":"train_df, validation_df, test_df = random_split(\n    balanced_df,0.7,0.1) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.437683Z","iopub.execute_input":"2025-10-19T11:51:41.437908Z","iopub.status.idle":"2025-10-19T11:51:41.451433Z","shell.execute_reply.started":"2025-10-19T11:51:41.437894Z","shell.execute_reply":"2025-10-19T11:51:41.450774Z"}},"outputs":[],"execution_count":11},{"id":"15219e40","cell_type":"code","source":"train_df.to_csv(\"train.csv\",index=None) \nvalidation_df.to_csv(\"validation.csv\",index=None) \ntest_df.to_csv(\"test.csv\",index=None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.452072Z","iopub.execute_input":"2025-10-19T11:51:41.452252Z","iopub.status.idle":"2025-10-19T11:51:41.474534Z","shell.execute_reply.started":"2025-10-19T11:51:41.452239Z","shell.execute_reply":"2025-10-19T11:51:41.473875Z"}},"outputs":[],"execution_count":12},{"id":"0eeee947","cell_type":"code","source":"# creating dat loaders \nimport tiktoken\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nprint(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:41.475339Z","iopub.execute_input":"2025-10-19T11:51:41.475555Z","iopub.status.idle":"2025-10-19T11:51:46.041193Z","shell.execute_reply.started":"2025-10-19T11:51:41.475541Z","shell.execute_reply":"2025-10-19T11:51:46.040467Z"}},"outputs":[{"name":"stdout","text":"[50256]\n","output_type":"stream"}],"execution_count":13},{"id":"cbdec4cf","cell_type":"code","source":"import torch \nfrom torch.utils.data import Dataset, DataLoader \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:46.041920Z","iopub.execute_input":"2025-10-19T11:51:46.042161Z","iopub.status.idle":"2025-10-19T11:51:49.642130Z","shell.execute_reply.started":"2025-10-19T11:51:46.042139Z","shell.execute_reply":"2025-10-19T11:51:49.641361Z"}},"outputs":[],"execution_count":14},{"id":"beba88ca","cell_type":"code","source":"class SpamDataset(Dataset): \n    def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id = 50256): \n        self.data = pd.read_csv(csv_file)\n        self.encoded_texts = [\n            tokenizer.encode(text) for text in self.data['Text']\n        ]\n        if max_length is None: \n            self.max_length = self._longest_encoded_lenght() \n        else: \n            self.max_length = max_length \n            self.encoded_texts = [\n                encoded_text[:self.max_length] \n                for encoded_text in self.encoded_texts\n            ] \n        self.encoded_texts = [\n            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n            for encoded_text in self.encoded_texts \n        ]\n\n    def __getitem__(self,index): \n        encoded = self.encoded_texts[index] \n        label  = self.data.iloc[index]['Label'] \n        return (\n            torch.tensor(encoded,dtype=torch.long), \n            torch.tensor(label,dtype=torch.long)\n        )\n    def __len__(self): \n        return len(self.data)\n\n    def _longest_encoded_lenght(self): \n        max_length = 0 \n        for encoded_text in self.encoded_texts: \n            encoded_lenght = len(encoded_text) \n            if encoded_lenght > max_length: \n                max_length = encoded_lenght \n        return max_length \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.642882Z","iopub.execute_input":"2025-10-19T11:51:49.643282Z","iopub.status.idle":"2025-10-19T11:51:49.650111Z","shell.execute_reply.started":"2025-10-19T11:51:49.643259Z","shell.execute_reply":"2025-10-19T11:51:49.649370Z"}},"outputs":[],"execution_count":15},{"id":"94beba87-f272-461a-90e0-3ca8ad22bb9a","cell_type":"code","source":"train_dataset = SpamDataset(\n    csv_file = \"train.csv\", \n    max_length = None , \n    tokenizer = tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.650970Z","iopub.execute_input":"2025-10-19T11:51:49.651209Z","iopub.status.idle":"2025-10-19T11:51:49.705650Z","shell.execute_reply.started":"2025-10-19T11:51:49.651187Z","shell.execute_reply":"2025-10-19T11:51:49.704877Z"}},"outputs":[],"execution_count":16},{"id":"893adaa5-59f8-425b-8040-fb85db782525","cell_type":"code","source":"print(train_dataset.max_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.706502Z","iopub.execute_input":"2025-10-19T11:51:49.706740Z","iopub.status.idle":"2025-10-19T11:51:49.711278Z","shell.execute_reply.started":"2025-10-19T11:51:49.706718Z","shell.execute_reply":"2025-10-19T11:51:49.710498Z"}},"outputs":[{"name":"stdout","text":"120\n","output_type":"stream"}],"execution_count":17},{"id":"7256e94e-4ad4-460e-8ef0-8974e77911c8","cell_type":"code","source":"val_dataset = SpamDataset(\ncsv_file=\"validation.csv\",\nmax_length=train_dataset.max_length,\ntokenizer=tokenizer\n)\ntest_dataset = SpamDataset(\ncsv_file=\"test.csv\",\nmax_length=train_dataset.max_length,\ntokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.712028Z","iopub.execute_input":"2025-10-19T11:51:49.712257Z","iopub.status.idle":"2025-10-19T11:51:49.746507Z","shell.execute_reply.started":"2025-10-19T11:51:49.712234Z","shell.execute_reply":"2025-10-19T11:51:49.745884Z"}},"outputs":[],"execution_count":18},{"id":"4af3521b-2f5c-42e3-a80a-27e580f29133","cell_type":"code","source":"from torch.utils.data import DataLoader ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.747334Z","iopub.execute_input":"2025-10-19T11:51:49.747564Z","iopub.status.idle":"2025-10-19T11:51:49.751199Z","shell.execute_reply.started":"2025-10-19T11:51:49.747545Z","shell.execute_reply":"2025-10-19T11:51:49.750503Z"}},"outputs":[],"execution_count":19},{"id":"aa87fa75-efa8-4c9f-ae19-79cc920a5a03","cell_type":"code","source":"num_workers = 0 \nbatch_size = 8 \ntorch.manual_seed(123) \n\ntrain_loader = DataLoader(\n    dataset = train_dataset, \n    batch_size = batch_size, \n    shuffle=True, \n    num_workers = num_workers, \n    drop_last=True\n)\nval_loader = DataLoader(\n    dataset = val_dataset, \n    batch_size = batch_size, \n    num_workers = num_workers, \n    drop_last = False\n)\n\ntest_loader = DataLoader(\n    dataset = test_dataset, \n    batch_size = batch_size, \n    num_workers = num_workers, \n    drop_last = False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.751864Z","iopub.execute_input":"2025-10-19T11:51:49.752028Z","iopub.status.idle":"2025-10-19T11:51:49.771013Z","shell.execute_reply.started":"2025-10-19T11:51:49.752016Z","shell.execute_reply":"2025-10-19T11:51:49.770198Z"}},"outputs":[],"execution_count":20},{"id":"338ecfbc-80b0-48fd-94e8-c83458b5fd0c","cell_type":"code","source":"for input_batch, target_batch in train_loader: \n    pass \nprint(\"Input batch dimenstions:\",input_batch.shape) \nprint(\"Label batch dimenstions:\",target_batch.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.771753Z","iopub.execute_input":"2025-10-19T11:51:49.772095Z","iopub.status.idle":"2025-10-19T11:51:49.919395Z","shell.execute_reply.started":"2025-10-19T11:51:49.772074Z","shell.execute_reply":"2025-10-19T11:51:49.918611Z"}},"outputs":[{"name":"stdout","text":"Input batch dimenstions: torch.Size([8, 120])\nLabel batch dimenstions: torch.Size([8])\n","output_type":"stream"}],"execution_count":21},{"id":"6e46e1a4-50a5-4d57-b2af-d39a79e503a1","cell_type":"code","source":"print(f\"{len(train_loader)} training batches\")\nprint(f\"{len(val_loader)} validation batches\")\nprint(f\"{len(test_loader)} test batches\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.924154Z","iopub.execute_input":"2025-10-19T11:51:49.924406Z","iopub.status.idle":"2025-10-19T11:51:49.928754Z","shell.execute_reply.started":"2025-10-19T11:51:49.924387Z","shell.execute_reply":"2025-10-19T11:51:49.927982Z"}},"outputs":[{"name":"stdout","text":"130 training batches\n19 validation batches\n38 test batches\n","output_type":"stream"}],"execution_count":22},{"id":"27969e87-072f-4dcd-a868-313bf07f1d76","cell_type":"code","source":"# initialize the model with pretrained weights \nCHOOSE_MODEL = \"gpt2-small (124M)\"\nINPUT_PROMPT = \"Every effort moves\"\n\nBASE_CONFIG = {\n    \"vocab_size\":50257,  \n    \"context_length\": 1024, \n    \"drop_rate\":0.0, \n    \"qkv_bias\":True\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.929463Z","iopub.execute_input":"2025-10-19T11:51:49.929703Z","iopub.status.idle":"2025-10-19T11:51:49.943998Z","shell.execute_reply.started":"2025-10-19T11:51:49.929684Z","shell.execute_reply":"2025-10-19T11:51:49.943248Z"}},"outputs":[],"execution_count":23},{"id":"a22a93e3-b657-4677-931e-671307bd03f1","cell_type":"code","source":"import torch.nn as nn \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.944764Z","iopub.execute_input":"2025-10-19T11:51:49.944946Z","iopub.status.idle":"2025-10-19T11:51:49.960908Z","shell.execute_reply.started":"2025-10-19T11:51:49.944931Z","shell.execute_reply":"2025-10-19T11:51:49.960186Z"}},"outputs":[],"execution_count":24},{"id":"9c974c63-5db9-401f-942b-30fcadc3beab","cell_type":"code","source":"model_configs = {\n\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.961706Z","iopub.execute_input":"2025-10-19T11:51:49.961973Z","iopub.status.idle":"2025-10-19T11:51:49.976743Z","shell.execute_reply.started":"2025-10-19T11:51:49.961949Z","shell.execute_reply":"2025-10-19T11:51:49.976005Z"}},"outputs":[],"execution_count":25},{"id":"269ed4e6-b822-4943-bc7b-f8e5ca0ebd81","cell_type":"code","source":"BASE_CONFIG.update(model_configs[CHOOSE_MODEL])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.977444Z","iopub.execute_input":"2025-10-19T11:51:49.977663Z","iopub.status.idle":"2025-10-19T11:51:49.991861Z","shell.execute_reply.started":"2025-10-19T11:51:49.977641Z","shell.execute_reply":"2025-10-19T11:51:49.991107Z"}},"outputs":[],"execution_count":26},{"id":"b39a23a7-83fb-469d-a6fc-ce2de1cd71a7","cell_type":"code","source":"# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n# Source for \"Build a Large Language Model From Scratch\"\n#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n# Code: https://github.com/rasbt/LLMs-from-scratch\n\n\nimport os\n\nimport requests\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tqdm import tqdm\n\n\ndef download_and_load_gpt2(model_size, models_dir):\n    # Validate model size\n    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n    if model_size not in allowed_sizes:\n        raise ValueError(f\"Model size not in {allowed_sizes}\")\n\n    # Define paths\n    model_dir = os.path.join(models_dir, model_size)\n    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n    filenames = [\n        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n        \"model.ckpt.meta\", \"vocab.bpe\"\n    ]\n\n    # Download files\n    os.makedirs(model_dir, exist_ok=True)\n    for filename in filenames:\n        file_url = os.path.join(base_url, model_size, filename)\n        backup_url = os.path.join(backup_base_url, model_size, filename)\n        file_path = os.path.join(model_dir, filename)\n        download_file(file_url, file_path, backup_url)\n\n    # Load settings and params\n    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n\n    return settings, params\n\n\ndef download_file(url, destination, backup_url=None):\n    def _attempt_download(download_url):\n        response = requests.get(download_url, stream=True, timeout=60)\n        response.raise_for_status()\n\n        file_size = int(response.headers.get(\"Content-Length\", 0))\n\n        # Check if file exists and has same size\n        if os.path.exists(destination):\n            file_size_local = os.path.getsize(destination)\n            if file_size and file_size == file_size_local:\n                print(f\"File already exists and is up-to-date: {destination}\")\n                return True\n\n        block_size = 1024  # 1 KB\n        desc = os.path.basename(download_url)\n        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n            with open(destination, \"wb\") as file:\n                for chunk in response.iter_content(chunk_size=block_size):\n                    if chunk:\n                        file.write(chunk)\n                        progress_bar.update(len(chunk))\n        return True\n\n    try:\n        if _attempt_download(url):\n            return\n    except requests.exceptions.RequestException:\n        if backup_url is not None:\n            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n            try:\n                if _attempt_download(backup_url):\n                    return\n            except requests.exceptions.RequestException:\n                pass\n\n        error_message = (\n            f\"Failed to download from both primary URL ({url})\"\n            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n            \"\\nCheck your internet connection or the file availability.\\n\"\n            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n        )\n        print(error_message)\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n\n\n# Alternative way using `requests`\n\"\"\"\ndef download_file(url, destination):\n    # Send a GET request to download the file in streaming mode\n    response = requests.get(url, stream=True)\n\n    # Get the total file size from headers, defaulting to 0 if not present\n    file_size = int(response.headers.get(\"content-length\", 0))\n\n    # Check if file exists and has the same size\n    if os.path.exists(destination):\n        file_size_local = os.path.getsize(destination)\n        if file_size == file_size_local:\n            print(f\"File already exists and is up-to-date: {destination}\")\n            return\n\n    # Define the block size for reading the file\n    block_size = 1024  # 1 Kilobyte\n\n    # Initialize the progress bar with total file size\n    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n        # Open the destination file in binary write mode\n        with open(destination, \"wb\") as file:\n            # Iterate over the file data in chunks\n            for chunk in response.iter_content(block_size):\n                progress_bar.update(len(chunk))  # Update progress bar\n                file.write(chunk)  # Write the chunk to the file\n\"\"\"\n\n\ndef load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n    # Initialize parameters dictionary with empty blocks for each layer\n    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n\n    # Iterate over each variable in the checkpoint\n    for name, _ in tf.train.list_variables(ckpt_path):\n        # Load the variable and remove singleton dimensions\n        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n\n        # Process the variable name to extract relevant parts\n        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n\n        # Identify the target dictionary for the variable\n        target_dict = params\n        if variable_name_parts[0].startswith(\"h\"):\n            layer_number = int(variable_name_parts[0][1:])\n            target_dict = params[\"blocks\"][layer_number]\n\n        # Recursively access or create nested dictionaries\n        for key in variable_name_parts[1:-1]:\n            target_dict = target_dict.setdefault(key, {})\n\n        # Assign the variable array to the last key\n        last_key = variable_name_parts[-1]\n        target_dict[last_key] = variable_array\n\n    return params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:51:49.992498Z","iopub.execute_input":"2025-10-19T11:51:49.992719Z","iopub.status.idle":"2025-10-19T11:52:02.718345Z","shell.execute_reply.started":"2025-10-19T11:51:49.992702Z","shell.execute_reply":"2025-10-19T11:52:02.717789Z"}},"outputs":[{"name":"stderr","text":"2025-10-19 11:51:51.498594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760874711.703181      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760874711.760589      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":27},{"id":"ceb89a3a-0a63-435a-aa63-5f911af70985","cell_type":"code","source":"\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads\n\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n\n        self.out_proj = nn.Linear(d_out, d_out)\n        self.dropout = nn.Dropout(dropout)\n\n        mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n        self.register_buffer(\"mask\", mask)\n\n    def forward(self, x):\n        B, T, D_in = x.shape\n\n        Q = self.W_query(x)  # (B, T, D_out)\n        K = self.W_key(x)    # (B, T, D_out)\n        V = self.W_value(x)  # (B, T, D_out)\n\n\n        Q = Q.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)  # (B, num_heads, T, head_dim)\n        K = K.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n        V = V.view(B, T, self.num_heads, self.head_dim).transpose(1, 2)\n\n        # Attention scores\n        attn_scores = (Q @ K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (B, num_heads, T, T)\n\n        mask = self.mask[:T, :T].bool()\n        attn_scores = attn_scores.masked_fill(mask[None, None, :, :], float('-inf'))\n\n        # Softmax and dropout\n        attn_weights = torch.softmax(attn_scores, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Apply attention\n        context = attn_weights @ V  # (B, num_heads, T, head_dim)\n\n        # Merge heads back\n        context = context.transpose(1, 2).contiguous().view(B, T, self.d_out)\n        context = self.out_proj(context)\n\n        return context\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.719009Z","iopub.execute_input":"2025-10-19T11:52:02.719487Z","iopub.status.idle":"2025-10-19T11:52:02.727445Z","shell.execute_reply.started":"2025-10-19T11:52:02.719469Z","shell.execute_reply":"2025-10-19T11:52:02.726631Z"}},"outputs":[],"execution_count":28},{"id":"1b8ec577-dbb3-47ef-89ed-3ca3b55e022f","cell_type":"code","source":"class GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n        (x + 0.044715 * torch.pow(x, 3))\n        ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.728194Z","iopub.execute_input":"2025-10-19T11:52:02.728486Z","iopub.status.idle":"2025-10-19T11:52:02.771810Z","shell.execute_reply.started":"2025-10-19T11:52:02.728463Z","shell.execute_reply":"2025-10-19T11:52:02.771144Z"}},"outputs":[],"execution_count":29},{"id":"1fe330e0-4d68-4328-8b6d-78cde1083eb6","cell_type":"code","source":"class FeedForward(nn.Module): \n    def __init__(self,cfg:dict): \n        super().__init__() \n        self.layers = nn.Sequential(\n            nn.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n            GELU(), \n            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n        )\n    \n    def forward(self,x): \n        return self.layers(x) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.772453Z","iopub.execute_input":"2025-10-19T11:52:02.772686Z","iopub.status.idle":"2025-10-19T11:52:02.787605Z","shell.execute_reply.started":"2025-10-19T11:52:02.772666Z","shell.execute_reply":"2025-10-19T11:52:02.786893Z"}},"outputs":[],"execution_count":30},{"id":"952b86e5-0760-4d87-871b-44eb2c4ccd51","cell_type":"code","source":"class LayerNorm(nn.Module): \n    def __init__(self,emb_dim): \n        super().__init__() \n        self.eps = 1e-5 \n        self.scale = nn.Parameter(torch.ones(emb_dim)) \n        self.shift = nn.Parameter(torch.zeros(emb_dim)) \n    \n    def forward(self,x): \n        mean = x.mean(dim=-1,keepdim=True) \n        var = x.var(dim=-1,keepdim=True,unbiased=False) \n        norm_x  = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift # we are not forcing them to be gausian , model \n        # can do what it whant here :) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.788201Z","iopub.execute_input":"2025-10-19T11:52:02.788379Z","iopub.status.idle":"2025-10-19T11:52:02.800992Z","shell.execute_reply.started":"2025-10-19T11:52:02.788366Z","shell.execute_reply":"2025-10-19T11:52:02.800349Z"}},"outputs":[],"execution_count":31},{"id":"25522503-61ab-4dcb-ad34-59826339fc11","cell_type":"code","source":"class TransformerBlock(nn.Module): \n    def __init__(self,cfg:dict):\n        super().__init__() \n        self.att = MultiHeadAttention(\n            d_in= cfg['emb_dim'],\n            d_out = cfg['emb_dim'], \n            context_length=cfg['context_length'], \n            num_heads = cfg['n_heads'], \n            dropout = cfg['drop_rate'], \n            qkv_bias=cfg['qkv_bias'] \n        )\n        self.ff = FeedForward(cfg) \n        self.norm1 = LayerNorm(cfg['emb_dim']) \n        self.norm2 = LayerNorm(cfg['emb_dim']) \n        self.drop_shortcut = nn.Dropout(cfg['drop_rate']) \n    \n    def forward(self,x): \n        shortcut = x \n        x = self.norm1(x) \n        x = self.att(x) \n        x = self.drop_shortcut(x) \n        x = x + shortcut \n\n        shortcut = x \n        x = self.norm2(x) \n        x = self.ff(x)  \n        x = self.drop_shortcut(x) \n        x = x + shortcut \n        return x \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.801699Z","iopub.execute_input":"2025-10-19T11:52:02.801914Z","iopub.status.idle":"2025-10-19T11:52:02.814627Z","shell.execute_reply.started":"2025-10-19T11:52:02.801901Z","shell.execute_reply":"2025-10-19T11:52:02.813966Z"}},"outputs":[],"execution_count":32},{"id":"2bc07f3f-d07e-4477-a981-b599e880adf7","cell_type":"code","source":"def assign(left, right):\n    if left.shape != right.shape:\n        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n        \"Right: {right.shape}\"\n    )\n    return torch.nn.Parameter(torch.tensor(right))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.815194Z","iopub.execute_input":"2025-10-19T11:52:02.815525Z","iopub.status.idle":"2025-10-19T11:52:02.831702Z","shell.execute_reply.started":"2025-10-19T11:52:02.815510Z","shell.execute_reply":"2025-10-19T11:52:02.831182Z"}},"outputs":[],"execution_count":33},{"id":"6c96581d-8287-476d-bf0f-298e7afc221d","cell_type":"code","source":"class GPTModel(nn.Module): \n    def __init__(self,cfg:dict): \n        super().__init__() \n        self.tok_emb = nn.Embedding(cfg['vocab_size'],cfg['emb_dim']) \n        self.pos_emb = nn.Embedding(cfg['context_length'],cfg['emb_dim']) \n        self.drop_emb = nn.Dropout(cfg['drop_rate']) \n\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n        )\n        self.final_norm = LayerNorm(cfg['emb_dim']) \n\n        self.out_head = nn.Linear( \n            cfg['emb_dim'], cfg['vocab_size'],bias=False\n        )\n    \n    def forward(self,in_idx:torch.Tensor): \n        batch_size, sq_len =  in_idx.shape \n        tok_embeds = self.tok_emb(in_idx)  \n        pos_embeds = self.pos_emb(\n            torch.arange(sq_len,device=in_idx.device)\n        )\n        x = tok_embeds + pos_embeds \n        x = self.drop_emb(x) \n        x = self.trf_blocks(x) \n        x = self.final_norm(x) \n        logits = self.out_head(x) \n        return logits ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.832272Z","iopub.execute_input":"2025-10-19T11:52:02.832482Z","iopub.status.idle":"2025-10-19T11:52:02.846510Z","shell.execute_reply.started":"2025-10-19T11:52:02.832468Z","shell.execute_reply":"2025-10-19T11:52:02.845845Z"}},"outputs":[],"execution_count":34},{"id":"d7238c32-1ada-4fa4-9305-bbd2b90332c2","cell_type":"code","source":"def generate_text_simple(model,idx,max_new_tokens,context_size): \n    for _ in range(max_new_tokens):\n        idx_cond = idx[:,-context_size:] \n        with torch.no_grad(): \n            logits = model(idx_cond) \n        logits = logits[:,-1,:]\n        probas = torch.softmax(logits,dim=-1) \n        idx_next = torch.argmax(probas,dim=-1,keepdim=True) \n        idx = torch.cat((idx,idx_next),dim=1) \n    return idx ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.847242Z","iopub.execute_input":"2025-10-19T11:52:02.847528Z","iopub.status.idle":"2025-10-19T11:52:02.862706Z","shell.execute_reply.started":"2025-10-19T11:52:02.847514Z","shell.execute_reply":"2025-10-19T11:52:02.861979Z"}},"outputs":[],"execution_count":35},{"id":"e1bdbac7-92ff-40b6-b16a-d580c0536a6f","cell_type":"code","source":"import numpy as np\ndef load_weights_into_gpt(gpt, params):\n    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n    for b in range(len(params[\"blocks\"])):\n        q_w, k_w, v_w = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.weight = assign(\n            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n        gpt.trf_blocks[b].att.W_key.weight = assign(\n            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n        gpt.trf_blocks[b].att.W_value.weight = assign(\n            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n        q_b, k_b, v_b = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.bias = assign(\n            gpt.trf_blocks[b].att.W_query.bias, q_b)\n        gpt.trf_blocks[b].att.W_key.bias = assign(\n            gpt.trf_blocks[b].att.W_key.bias, k_b)\n        gpt.trf_blocks[b].att.W_value.bias = assign(\n            gpt.trf_blocks[b].att.W_value.bias, v_b)\n        gpt.trf_blocks[b].att.out_proj.weight = assign(\n            gpt.trf_blocks[b].att.out_proj.weight,\n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].att.out_proj.bias = assign(\n            gpt.trf_blocks[b].att.out_proj.bias,\n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n            gpt.trf_blocks[b].ff.layers[0].weight,\n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n            gpt.trf_blocks[b].ff.layers[0].bias,\n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n            gpt.trf_blocks[b].ff.layers[2].weight,\n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n            gpt.trf_blocks[b].ff.layers[2].bias,\n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n        gpt.trf_blocks[b].norm1.scale = assign(\n            gpt.trf_blocks[b].norm1.scale,\n            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n        gpt.trf_blocks[b].norm1.shift = assign(\n            gpt.trf_blocks[b].norm1.shift,\n            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n        gpt.trf_blocks[b].norm2.scale = assign(\n            gpt.trf_blocks[b].norm2.scale,\n            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n        gpt.trf_blocks[b].norm2.shift = assign(\n            gpt.trf_blocks[b].norm2.shift,\n            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.863447Z","iopub.execute_input":"2025-10-19T11:52:02.863837Z","iopub.status.idle":"2025-10-19T11:52:02.876769Z","shell.execute_reply.started":"2025-10-19T11:52:02.863821Z","shell.execute_reply":"2025-10-19T11:52:02.876104Z"}},"outputs":[],"execution_count":36},{"id":"755df43d-cbb0-4fff-a012-546c3e7fba83","cell_type":"code","source":"model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\nsettings, params = download_and_load_gpt2(\nmodel_size=model_size, models_dir=\"gpt2\"\n)\nmodel = GPTModel(BASE_CONFIG)\nload_weights_into_gpt(model, params)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:02.877345Z","iopub.execute_input":"2025-10-19T11:52:02.877546Z","iopub.status.idle":"2025-10-19T11:54:20.302253Z","shell.execute_reply.started":"2025-10-19T11:52:02.877532Z","shell.execute_reply":"2025-10-19T11:54:20.301636Z"}},"outputs":[{"name":"stderr","text":"checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 157kiB/s]\nencoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 692kiB/s] \nhparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 166kiB/s]\nmodel.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:06<00:00, 3.94MiB/s]   \nmodel.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.41MiB/s]\nmodel.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 467kiB/s]  \nvocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 390kiB/s]  \n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":37},{"id":"6c58b28f-64da-40f6-941e-fd239ee515c0","cell_type":"code","source":"def text_to_token_ids(text,tokenizer): \n    encoded = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"}) \n    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n    return encoded_tensor ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:20.302994Z","iopub.execute_input":"2025-10-19T11:54:20.303201Z","iopub.status.idle":"2025-10-19T11:54:20.307118Z","shell.execute_reply.started":"2025-10-19T11:54:20.303177Z","shell.execute_reply":"2025-10-19T11:54:20.306462Z"}},"outputs":[],"execution_count":38},{"id":"f198a18d-cac9-4057-aa30-ba21bfcf2edf","cell_type":"code","source":"def token_ids_to_text(token_ids:torch.Tensor,tokenizer): \n    flat = token_ids.squeeze(0) # remove batch dimenstion \n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:20.307861Z","iopub.execute_input":"2025-10-19T11:54:20.308131Z","iopub.status.idle":"2025-10-19T11:54:20.321656Z","shell.execute_reply.started":"2025-10-19T11:54:20.308117Z","shell.execute_reply":"2025-10-19T11:54:20.321099Z"}},"outputs":[],"execution_count":39},{"id":"8bb58158-a7f5-40af-8927-05b5d7b9db45","cell_type":"code","source":"text_1 = \"Every effort moves you\"\ntoken_ids = generate_text_simple(\nmodel=model,\nidx=text_to_token_ids(text_1, tokenizer),\nmax_new_tokens=15,\ncontext_size=BASE_CONFIG[\"context_length\"]\n)\nprint(token_ids_to_text(token_ids, tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:20.322441Z","iopub.execute_input":"2025-10-19T11:54:20.322665Z","iopub.status.idle":"2025-10-19T11:54:21.588672Z","shell.execute_reply.started":"2025-10-19T11:54:20.322644Z","shell.execute_reply":"2025-10-19T11:54:21.587979Z"}},"outputs":[{"name":"stdout","text":"Every effort moves you forward.\n\nThe first step is to understand the importance of your work\n","output_type":"stream"}],"execution_count":40},{"id":"7a2f8b3f-18a0-4b14-a7aa-29478d035ae3","cell_type":"code","source":"text_2 = (\n\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n\" 'You are a winner you have been specially\"\n\" selected to receive $1000 cash or a $2000 award.'\"\n)\ntoken_ids = generate_text_simple(\nmodel=model,\nidx=text_to_token_ids(text_2, tokenizer),\nmax_new_tokens=23,\ncontext_size=BASE_CONFIG[\"context_length\"]\n)\nprint(token_ids_to_text(token_ids, tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:21.589369Z","iopub.execute_input":"2025-10-19T11:54:21.589694Z","iopub.status.idle":"2025-10-19T11:54:24.396651Z","shell.execute_reply.started":"2025-10-19T11:54:21.589675Z","shell.execute_reply":"2025-10-19T11:54:24.395833Z"}},"outputs":[{"name":"stdout","text":"Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n\nThe following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n","output_type":"stream"}],"execution_count":41},{"id":"b25211e0-a346-4656-b9bb-67e1f7fec0c3","cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.397426Z","iopub.execute_input":"2025-10-19T11:54:24.397732Z","iopub.status.idle":"2025-10-19T11:54:24.402988Z","shell.execute_reply.started":"2025-10-19T11:54:24.397708Z","shell.execute_reply":"2025-10-19T11:54:24.402331Z"}},"outputs":[{"name":"stdout","text":"GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)\n","output_type":"stream"}],"execution_count":42},{"id":"527ffe8f-b4a2-48da-b9b9-43a324d68485","cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.403797Z","iopub.execute_input":"2025-10-19T11:54:24.404070Z","iopub.status.idle":"2025-10-19T11:54:24.416977Z","shell.execute_reply.started":"2025-10-19T11:54:24.404054Z","shell.execute_reply":"2025-10-19T11:54:24.416228Z"}},"outputs":[],"execution_count":43},{"id":"b8c87f4b-7ad4-4764-98dc-45ad03abb641","cell_type":"code","source":"torch.manual_seed(123)\nnum_classes = 2\nmodel.out_head = torch.nn.Linear(\nin_features=BASE_CONFIG[\"emb_dim\"],\nout_features=num_classes\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.417755Z","iopub.execute_input":"2025-10-19T11:54:24.417972Z","iopub.status.idle":"2025-10-19T11:54:24.434846Z","shell.execute_reply.started":"2025-10-19T11:54:24.417953Z","shell.execute_reply":"2025-10-19T11:54:24.434289Z"}},"outputs":[],"execution_count":44},{"id":"ac91410f-0737-4925-bb2f-854a4ef9da58","cell_type":"code","source":"for param in model.trf_blocks[-1].parameters():\n    param.requires_grad = True\nfor param in model.final_norm.parameters():\n    param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.435621Z","iopub.execute_input":"2025-10-19T11:54:24.435827Z","iopub.status.idle":"2025-10-19T11:54:24.461657Z","shell.execute_reply.started":"2025-10-19T11:54:24.435814Z","shell.execute_reply":"2025-10-19T11:54:24.461177Z"}},"outputs":[],"execution_count":45},{"id":"5b845223-f263-41f1-8254-15e8fba5a011","cell_type":"code","source":"inputs = tokenizer.encode(\"Do you have time\")\ninputs = torch.tensor(inputs).unsqueeze(0)\nprint(\"Inputs:\", inputs)\nprint(\"Inputs dimensions:\", inputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.462236Z","iopub.execute_input":"2025-10-19T11:54:24.462434Z","iopub.status.idle":"2025-10-19T11:54:24.470699Z","shell.execute_reply.started":"2025-10-19T11:54:24.462421Z","shell.execute_reply":"2025-10-19T11:54:24.470087Z"}},"outputs":[{"name":"stdout","text":"Inputs: tensor([[5211,  345,  423,  640]])\nInputs dimensions: torch.Size([1, 4])\n","output_type":"stream"}],"execution_count":46},{"id":"ab587a2b-c15e-4aec-b2fa-22491f7ca728","cell_type":"code","source":"with torch.no_grad():\n    outputs = model(inputs)\n    print(\"Outputs:\\n\", outputs)\n    print(\"Outputs dimensions:\", outputs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.471373Z","iopub.execute_input":"2025-10-19T11:54:24.471844Z","iopub.status.idle":"2025-10-19T11:54:24.537815Z","shell.execute_reply.started":"2025-10-19T11:54:24.471822Z","shell.execute_reply":"2025-10-19T11:54:24.537226Z"}},"outputs":[{"name":"stdout","text":"Outputs:\n tensor([[[-1.5854,  0.9904],\n         [-3.7235,  7.4548],\n         [-2.2661,  6.6049],\n         [-3.5983,  3.9902]]])\nOutputs dimensions: torch.Size([1, 4, 2])\n","output_type":"stream"}],"execution_count":47},{"id":"5d3b003c-d43f-45e7-970c-6375e76d9eec","cell_type":"code","source":"print(\"Last output token:\", outputs[:, -1, :])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.538455Z","iopub.execute_input":"2025-10-19T11:54:24.538669Z","iopub.status.idle":"2025-10-19T11:54:24.542968Z","shell.execute_reply.started":"2025-10-19T11:54:24.538654Z","shell.execute_reply":"2025-10-19T11:54:24.542458Z"}},"outputs":[{"name":"stdout","text":"Last output token: tensor([[-3.5983,  3.9902]])\n","output_type":"stream"}],"execution_count":48},{"id":"d7e2b211-b946-405c-ad28-e8e988229a04","cell_type":"code","source":"print(\"Last output token:\", outputs[:, -1, :])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.543565Z","iopub.execute_input":"2025-10-19T11:54:24.544123Z","iopub.status.idle":"2025-10-19T11:54:24.556363Z","shell.execute_reply.started":"2025-10-19T11:54:24.544107Z","shell.execute_reply":"2025-10-19T11:54:24.555808Z"}},"outputs":[{"name":"stdout","text":"Last output token: tensor([[-3.5983,  3.9902]])\n","output_type":"stream"}],"execution_count":49},{"id":"52ced38c-262a-4fb9-9bf0-b273814fc299","cell_type":"code","source":"probas = torch.softmax(outputs[:, -1, :], dim=-1)\nlabel = torch.argmax(probas)\nprint(\"Class label:\", label.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.556907Z","iopub.execute_input":"2025-10-19T11:54:24.557056Z","iopub.status.idle":"2025-10-19T11:54:24.568884Z","shell.execute_reply.started":"2025-10-19T11:54:24.557045Z","shell.execute_reply":"2025-10-19T11:54:24.568229Z"}},"outputs":[{"name":"stdout","text":"Class label: 1\n","output_type":"stream"}],"execution_count":50},{"id":"5b98f36c-6402-4b6e-9538-ed00187ca944","cell_type":"code","source":"logits = outputs[:, -1, :]\nlabel = torch.argmax(logits)\nprint(\"Class label:\", label.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.569564Z","iopub.execute_input":"2025-10-19T11:54:24.569799Z","iopub.status.idle":"2025-10-19T11:54:24.582104Z","shell.execute_reply.started":"2025-10-19T11:54:24.569779Z","shell.execute_reply":"2025-10-19T11:54:24.581477Z"}},"outputs":[{"name":"stdout","text":"Class label: 1\n","output_type":"stream"}],"execution_count":51},{"id":"8d5e7f5d-93bd-463f-b94e-dd9b045b212a","cell_type":"code","source":"def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n    model.eval() \n    correct_predictions, num_examples=0,0\n    if num_batches is None: \n        num_batches = len(data_loader)\n    else: \n        num_batches = min(num_batches,len(data_loader))\n    for i, (input_batch,target_batch) in enumerate(data_loader): \n        if i < num_batches: \n            input_batch = input_batch.to(device)\n            target_batch = target_batch.to(device)\n            with torch.no_grad():\n                logits = model(input_batch)[:,-1,:] # logits of last ouput token\n            predicted_labels  = torch.argmax(logits,dim=-1)\n            num_examples += predicted_labels.shape[0] # how many examples in the batch \n            correct_predictions += (\n                (predicted_labels == target_batch).sum().item()\n            )\n        else:\n            break\n    return correct_predictions / num_examples ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.582887Z","iopub.execute_input":"2025-10-19T11:54:24.583304Z","iopub.status.idle":"2025-10-19T11:54:24.597386Z","shell.execute_reply.started":"2025-10-19T11:54:24.583284Z","shell.execute_reply":"2025-10-19T11:54:24.596768Z"}},"outputs":[],"execution_count":52},{"id":"951f7a4e-cabd-4f0e-a841-8995d04cd7d6","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \nmodel.to(device) \ntorch.manual_seed(123)\ntrain_accuracy = calc_accuracy_loader(\ntrain_loader, model, device, num_batches=10\n)\nval_accuracy = calc_accuracy_loader(\nval_loader, model, device, num_batches=10\n)\ntest_accuracy = calc_accuracy_loader(\ntest_loader, model, device, num_batches=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:24.597985Z","iopub.execute_input":"2025-10-19T11:54:24.598140Z","iopub.status.idle":"2025-10-19T11:54:26.524600Z","shell.execute_reply.started":"2025-10-19T11:54:24.598128Z","shell.execute_reply":"2025-10-19T11:54:26.523994Z"}},"outputs":[],"execution_count":53},{"id":"9b0369e8-2b5d-427e-b751-49a2a48ad476","cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch = input_batch.to(device)\n    target_batch = target_batch.to(device)\n    logits = model(input_batch)[:, -1, :]\n    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:26.525380Z","iopub.execute_input":"2025-10-19T11:54:26.525639Z","iopub.status.idle":"2025-10-19T11:54:26.529715Z","shell.execute_reply.started":"2025-10-19T11:54:26.525617Z","shell.execute_reply":"2025-10-19T11:54:26.529010Z"}},"outputs":[],"execution_count":54},{"id":"eafcd69e-8704-48fa-8b13-f752012ac6e7","cell_type":"code","source":"def calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0. \n    if len(data_loader) == 0: \n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        num_batches = min(num_batches,len(data_loader))\n    for i, (input_batch,target_batch) in enumerate(data_loader): \n        if i < num_batches:\n            loss = calc_loss_batch(\n                input_batch,target_batch,model,device\n            )\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:26.530398Z","iopub.execute_input":"2025-10-19T11:54:26.530660Z","iopub.status.idle":"2025-10-19T11:54:26.544889Z","shell.execute_reply.started":"2025-10-19T11:54:26.530645Z","shell.execute_reply":"2025-10-19T11:54:26.544432Z"}},"outputs":[],"execution_count":55},{"id":"2e4c74b1-9e2a-4a70-9be9-91dbc701d562","cell_type":"code","source":"with torch.no_grad(): \n    train_loss  = calc_loss_loader(\n        train_loader,model,device,num_batches=5\n    )\n    val_loss = calc_loss_loader(val_loader,model,device,num_batches=5)\n    test_loss = calc_loss_loader(test_loader,model,device,num_batches=5) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:26.545672Z","iopub.execute_input":"2025-10-19T11:54:26.545963Z","iopub.status.idle":"2025-10-19T11:54:27.127207Z","shell.execute_reply.started":"2025-10-19T11:54:26.545943Z","shell.execute_reply":"2025-10-19T11:54:27.126655Z"}},"outputs":[],"execution_count":56},{"id":"3e33b255-e9c5-41b3-bce1-818f6f5d39be","cell_type":"code","source":"print(f\"Training loss: {train_loss:.3f}\")\nprint(f\"Validation loss: {val_loss:.3f}\")\nprint(f\"Test loss: {test_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:27.127944Z","iopub.execute_input":"2025-10-19T11:54:27.128142Z","iopub.status.idle":"2025-10-19T11:54:27.132196Z","shell.execute_reply.started":"2025-10-19T11:54:27.128126Z","shell.execute_reply":"2025-10-19T11:54:27.131595Z"}},"outputs":[{"name":"stdout","text":"Training loss: 2.450\nValidation loss: 2.565\nTest loss: 2.325\n","output_type":"stream"}],"execution_count":57},{"id":"23cae55d-492b-496e-bb4e-895b3ef4cbfb","cell_type":"code","source":"def train_classifier_simple(\n    model,train_loader,val_loader,optimizer,device,\n    num_epochs,eval_freq,eval_iter):\n    train_losses,val_losses,train_accs,val_accs = [],[],[],[]\n    examples_seen,global_step = 0, -1\n    for epoch in range(num_epochs):\n        model.train()\n        for input_batch,target_batch in train_loader:\n            optimizer.zero_grad()\n            loss = calc_loss_batch(\n                input_batch,target_batch,model,device\n            )\n            loss.backward()\n            optimizer.step()\n            examples_seen += input_batch.shape[0] # how many examples in the batch\n            global_step +=1\n            if global_step % eval_freq == 0:\n                train_loss, val_loss = evaluate_model(\n                    model,train_loader,val_loader,device,eval_iter\n                )\n                train_losses.append(train_loss)\n                val_losses.append(val_losses)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                    f\"Train loss {train_loss:.3f}, \"\n                    f\"Val loss {val_loss:.3f}\"\n                    )\n        train_accuracy = calc_accuracy_loader(\n            val_loader,model,device,num_batches=eval_iter\n        )\n        val_accuracy = calc_accuracy_loader(\n            val_loader,model,device,num_batches=eval_iter\n        )\n        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n        train_accs.append(train_accuracy)\n        val_accs.append(val_accuracy)\n    return train_losses, val_losses, train_accs, val_accs, examples_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:27.132985Z","iopub.execute_input":"2025-10-19T11:54:27.133267Z","iopub.status.idle":"2025-10-19T11:54:27.146213Z","shell.execute_reply.started":"2025-10-19T11:54:27.133252Z","shell.execute_reply":"2025-10-19T11:54:27.145714Z"}},"outputs":[],"execution_count":58},{"id":"f483082a-9293-40fe-b164-e34e0b84b7e5","cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(\n        train_loader, model, device, num_batches=eval_iter\n        )\n        val_loss = calc_loss_loader(\n        val_loader, model, device, num_batches=eval_iter\n        )\n    model.train()\n    return train_loss, val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:27.146848Z","iopub.execute_input":"2025-10-19T11:54:27.147033Z","iopub.status.idle":"2025-10-19T11:54:27.163462Z","shell.execute_reply.started":"2025-10-19T11:54:27.147020Z","shell.execute_reply":"2025-10-19T11:54:27.162790Z"}},"outputs":[],"execution_count":59},{"id":"b29e224a-f870-45c0-8cbd-a687a738fa68","cell_type":"code","source":"import time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:27.164020Z","iopub.execute_input":"2025-10-19T11:54:27.164211Z","iopub.status.idle":"2025-10-19T11:54:27.177521Z","shell.execute_reply.started":"2025-10-19T11:54:27.164197Z","shell.execute_reply":"2025-10-19T11:54:27.176892Z"}},"outputs":[],"execution_count":60},{"id":"04d00725-3403-4d7b-a164-109f85bed6fb","cell_type":"code","source":"start_time = time.time()\ntorch.manual_seed(123)\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\nnum_epochs = 5\ntrain_losses, val_losses, train_accs, val_accs, examples_seen = \\\ntrain_classifier_simple(\nmodel, train_loader, val_loader, optimizer, device,\nnum_epochs=num_epochs, eval_freq=50,\neval_iter=5\n)\nend_time = time.time()\nexecution_time_minutes = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time_minutes:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:54:27.178141Z","iopub.execute_input":"2025-10-19T11:54:27.178403Z","iopub.status.idle":"2025-10-19T11:55:05.782462Z","shell.execute_reply.started":"2025-10-19T11:54:27.178379Z","shell.execute_reply":"2025-10-19T11:55:05.781840Z"}},"outputs":[{"name":"stdout","text":"Ep 1 (Step 000000): Train loss 2.160, Val loss 2.374\nEp 1 (Step 000050): Train loss 0.654, Val loss 0.631\nEp 1 (Step 000100): Train loss 0.531, Val loss 0.566\nTraining accuracy: 75.00% | Validation accuracy: 75.00%\nEp 2 (Step 000150): Train loss 0.561, Val loss 0.462\nEp 2 (Step 000200): Train loss 0.537, Val loss 0.390\nEp 2 (Step 000250): Train loss 0.284, Val loss 0.340\nTraining accuracy: 90.00% | Validation accuracy: 90.00%\nEp 3 (Step 000300): Train loss 0.488, Val loss 0.336\nEp 3 (Step 000350): Train loss 0.291, Val loss 0.305\nTraining accuracy: 97.50% | Validation accuracy: 97.50%\nEp 4 (Step 000400): Train loss 0.110, Val loss 0.114\nEp 4 (Step 000450): Train loss 0.075, Val loss 0.078\nEp 4 (Step 000500): Train loss 0.012, Val loss 0.051\nTraining accuracy: 100.00% | Validation accuracy: 100.00%\nEp 5 (Step 000550): Train loss 0.173, Val loss 0.053\nEp 5 (Step 000600): Train loss 0.189, Val loss 0.087\nTraining accuracy: 97.50% | Validation accuracy: 97.50%\nTraining completed in 0.64 minutes.\n","output_type":"stream"}],"execution_count":61},{"id":"92b51934-f5d3-4745-95c5-cc01b7b8fae3","cell_type":"code","source":"import matplotlib.pyplot as plt \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:55:05.783122Z","iopub.execute_input":"2025-10-19T11:55:05.783648Z","iopub.status.idle":"2025-10-19T11:55:05.787015Z","shell.execute_reply.started":"2025-10-19T11:55:05.783630Z","shell.execute_reply":"2025-10-19T11:55:05.786277Z"}},"outputs":[],"execution_count":62},{"id":"8b236664-26d6-4601-b414-48ddae36ed1f","cell_type":"code","source":"def plot_values(\n    epochs_seen,examples_seen,train_values,val_values,label=\"loss\"):\n    fig, ax1 = plt.subplots(figsize=(5,3))\n    ax1.plot(epochs_seen,train_values,label=f\"Training {label}\")\n    ax1.plot(\n        epochs_seen,val_values,linestyle=\"-.\",\n        label=f\"Validation {label}\"\n    )\n    ax1.set_xlabel(\"Epochs\")\n    ax1.set_ylabel(label.capitalize())\n    ax1.legend()\n    ax2 = ax1.twiny()\n    ax2.plot(examples_seen,train_values,alpha=0)\n    ax2.set_xlabel(\"Example Seen\")\n    fig.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:55:05.787778Z","iopub.execute_input":"2025-10-19T11:55:05.788238Z","iopub.status.idle":"2025-10-19T11:55:05.802831Z","shell.execute_reply.started":"2025-10-19T11:55:05.788210Z","shell.execute_reply":"2025-10-19T11:55:05.802217Z"}},"outputs":[],"execution_count":63},{"id":"44e7c1d0-5a36-4ef6-bb39-27b5574d8b6e","cell_type":"code","source":"epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\nexamples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\nplot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:55:05.803372Z","iopub.execute_input":"2025-10-19T11:55:05.803553Z","execution_failed":"2025-10-19T11:58:51.993Z"}},"outputs":[],"execution_count":null},{"id":"b916427c-9271-4b05-aa6c-83150f04eb5a","cell_type":"code","source":"epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\nexamples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\nplot_values(\nepochs_tensor, examples_seen_tensor, train_accs, val_accs,\nlabel=\"accuracy\"\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-19T11:58:51.993Z"}},"outputs":[],"execution_count":null},{"id":"86cf1514-83b7-4c9e-9cbd-f63e9da508cf","cell_type":"code","source":"train_accuracy = calc_accuracy_loader(train_loader, model, device)\nval_accuracy = calc_accuracy_loader(val_loader, model, device)\ntest_accuracy = calc_accuracy_loader(test_loader, model, device)\nprint(f\"Training accuracy: {train_accuracy*100:.2f}%\")\nprint(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\nprint(f\"Test accuracy: {test_accuracy*100:.2f}%\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-19T11:58:51.994Z"}},"outputs":[],"execution_count":null},{"id":"02444756-6aed-4002-ac6b-8a8ffb2ae144","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}